{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8cec84c-72c4-4916-a02d-e7f8cc9fe71a",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea82793-83b3-4dab-bc2f-7bad3b04f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose a data set\n",
    "data_set = \"Breast Cancer\"\n",
    "\n",
    "#Choose how to impute tabular data\n",
    "imputer = \"zero_imp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e3fe8f-f205-4f06-810e-baef724b01d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/kimvc/.conda/envs/my_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-16 19:13:28.919936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-16 19:13:29.057391: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-16 19:13:30.720537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/pkg/nccl/nccl-2.18.1-cuda11.8/lib64:/usr/local/pkg/cuda/cuda-11.8/lib64:/usr/local/pkg/cuda/cuda-11.8/cuda/lib64\n",
      "2025-03-16 19:13:30.720613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/pkg/nccl/nccl-2.18.1-cuda11.8/lib64:/usr/local/pkg/cuda/cuda-11.8/lib64:/usr/local/pkg/cuda/cuda-11.8/cuda/lib64\n",
      "2025-03-16 19:13:30.720619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, logging, LongformerModel, LongformerTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "\n",
    "with open('configs/config_' + data_set+ '.json') as config_file:\n",
    "        UCI_config = json.load(config_file)\n",
    "\n",
    "\"\"\n",
    "           #Load data and parameters\n",
    "\"\"\n",
    "EXAMPLE_PATH = UCI_config[\"EXAMPLE_PATH\"]\n",
    "TABLES_FILE = UCI_config[\"TABLES_FILE\"]\n",
    "COLUMNS_PATH = UCI_config[\"COLUMNS_PATH\"]\n",
    "ID_COL = UCI_config[\"ID_COL\"]\n",
    "TARGET_FILE = UCI_config[\"TARGET_INFO_FILE\"]\n",
    "TARGET_COL = UCI_config[\"TARGET_COL\"]\n",
    "split_seed = UCI_config[\"TARGET_SPLIT_SEED\"]\n",
    "split_ratio = UCI_config[\"TEST_SPLIT_RATIO\"]\n",
    "TIME_COL = None\n",
    "\n",
    "sys.path.insert(0, './../../src')\n",
    "from get_data_info import *\n",
    "from get_patients import *\n",
    "from get_features import *\n",
    "from train_models import *\n",
    "\n",
    "DATA_PATH = EXAMPLE_PATH + UCI_config[\"RAW_DATA_PATH\"] \n",
    "paths = [EXAMPLE_PATH, DATA_PATH, TABLES_FILE, COLUMNS_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc3adec-da94-480b-8b0e-5f0c2c96d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file with the targets\n",
    "targets_df = pd.read_csv(TARGET_FILE)\n",
    "\n",
    "#split into training and testing sets\n",
    "train_df, test_df = train_test_split(targets_df, test_size=split_ratio, random_state=split_seed, stratify=targets_df[TARGET_COL])\n",
    "\n",
    "#find the subject ids for training and testing\n",
    "training_ids = train_df[ID_COL].unique()\n",
    "testing_ids = test_df[ID_COL].unique()\n",
    "\n",
    "#save all the model information\n",
    "save_model_info(paths, ID_COL, TIME_COL, imputer, training_ids, testing_ids, model_name=data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9e4149-3a42-4443-b089-4aa7d0b78267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose text and llm settings\n",
    "prefix = \"\"\n",
    "missing = \"\"\n",
    "replace = True\n",
    "descriptive = True\n",
    "meta = True\n",
    "clinical = True\n",
    "long = True\n",
    "biogpt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f842cd0-56f9-4212-a330-b372a07c06da",
   "metadata": {},
   "source": [
    "## FineTuning Model \n",
    "We use the textual data from the training set to fine-tune the model (in this case Clinical Longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a62129-b3af-4430-a472-c1445e059921",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"\"\n",
    "original_llm_path = \"\"\n",
    "\n",
    "if long:\n",
    "    if clinical:\n",
    "        original_llm_path = \"./../../LLMs/ClinicalLongformer/\"\n",
    "        llm_name = \"ClinicalLongformer\"\n",
    "    else:\n",
    "        original_llm_path = \"./../../LLMs/Longformer/\"\n",
    "        llm_name = \"Longformer\"\n",
    "if biogpt:\n",
    "    assert(long==False)\n",
    "    assert(clinical==False)\n",
    "    assert(finetuned==False)\n",
    "    llm_name = \"BioGPT\"\n",
    "    \n",
    "folder_name = \"Training/\" + llm_name + \"/\" + data_set + \"/\"\n",
    "sent_name = \"RAW_DATA_\" + str(prefix) +\"_\"+ str(missing) +\"_\"+ str(replace) +\"_\"+ str(descriptive) +\"_\"+ str(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b69193-4e24-4176-972c-27fd65f950e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text data for the training set\n",
    "tables_info, global_imputer, all_ids = get_model_info(paths, ID_COL, TIME_COL, imputer, \"Training\", None, model_name=data_set)\n",
    "get_and_save_pickle_patients(tables_info, ID_COL, TIME_COL, all_ids, prefix, missing, replace, descriptive, meta, global_imputer, folder_name, EXAMPLE_PATH, \"RAW_DATA\", clinical, long, biogpt, \"\" , [\"text\"])\n",
    "get_and_save_features(all_ids, TIME_COL, ID_COL, [\"text\"], None, folder_name, EXAMPLE_PATH, sent_name, job_id=(str(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8721f255-1605-42fc-8a49-a16e8a9ddcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./../../LLMs/ClinicalLongformer/model were not used when initializing LongformerForMaskedLM: ['longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using cuda_amp half precision backend                         \n",
      "The following columns in the training set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 180\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 315\n",
      "  Number of trainable parameters = 148711257\n",
      "You're using a LongformerTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 01:50, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.180600</td>\n",
       "      <td>0.181715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.128674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.069346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.050183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.036963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.033436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.056211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Breast Cancer_finetuned\n",
      "Configuration saved in Breast Cancer_finetuned/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in Breast Cancer_finetuned/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#Finetune the pretrained model\n",
    "X_text = pd.read_csv(folder_name + \"text/\" + sent_name + \"/Features/0.csv\", index_col=0)\n",
    "X_train = X_text[[ID_COL, \"text\"]]\n",
    "fine_tune(X_train, original_llm_path, data_set, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b7096-ee41-4669-a253-7e4c0a82ef78",
   "metadata": {},
   "source": [
    "## Create Tabtext Embeddings \n",
    "We next create embeddings for training and testing sets using the finetuned llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc1c943-9168-48f7-aab6-053c19865fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select finetuned or not finetuned model\n",
    "finetuned = True\n",
    "feature_types = [\"sep_imputations\", \"sep_embeddings\"]\n",
    "\n",
    "llm_name = \"\"\n",
    "\n",
    "if long:\n",
    "    if clinical:\n",
    "        if finetuned:\n",
    "            llm_name = \"ClinicalLongformerFinetuned\"\n",
    "            finetuned_path = data_set + \"_finetuned\"\n",
    "        else:\n",
    "            llm_name = \"ClinicalLongformer\"\n",
    "    else:\n",
    "        if finetuned:\n",
    "            llm_name = \"LongformerFinetuned\"\n",
    "            finetuned_path = data_set + \"_finetuned\"\n",
    "        else:\n",
    "            llm_name = \"Longformer\"\n",
    "if biogpt:\n",
    "    assert(long==False)\n",
    "    assert(clinical==False)\n",
    "    assert(finetuned==False)\n",
    "    llm_name = \"BioGPT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54789a02-48a5-4a74-8545-04f0d2112703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set the logging level to WARNING (this will suppress INFO messages like \"loading file ...\")\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "\n",
    "#Training embeddings\n",
    "folder_name = \"Training/\" + llm_name + \"/\" + data_set + \"/\"\n",
    "tables_info, global_imputer, all_ids = get_model_info(paths, ID_COL, TIME_COL, imputer, \"Training\", None, model_name=data_set)\n",
    "get_and_save_pickle_patients(tables_info, ID_COL, TIME_COL, all_ids, prefix, missing, replace, descriptive, meta, global_imputer, folder_name, EXAMPLE_PATH, \"RAW_DATA\", clinical, long, biogpt, finetuned_path, feature_types)\n",
    "\n",
    "sent_name = \"RAW_DATA_\" + str(prefix) +\"_\"+ str(missing) +\"_\"+ str(replace) +\"_\"+ str(descriptive) +\"_\"+ str(meta)\n",
    "get_and_save_features(all_ids, TIME_COL, ID_COL, feature_types, None, folder_name, EXAMPLE_PATH, sent_name, job_id=\"0\")\n",
    "\n",
    "\n",
    "#Testing embeddings\n",
    "folder_name = \"Testing/\" + llm_name + \"/\" + data_set + \"/\"\n",
    "tables_info, global_imputer, all_ids = get_model_info(paths, ID_COL, TIME_COL, imputer, \"Testing\", None, model_name=data_set)\n",
    "get_and_save_pickle_patients(tables_info, ID_COL, TIME_COL, all_ids, prefix, missing, replace, descriptive, meta, global_imputer, folder_name, EXAMPLE_PATH, \"RAW_DATA\", clinical, long, biogpt, finetuned_path, feature_types)\n",
    "\n",
    "sent_name = \"RAW_DATA_\" + str(prefix) +\"_\"+ str(missing) +\"_\"+ str(replace) +\"_\"+ str(descriptive) +\"_\"+ str(meta)\n",
    "get_and_save_features(all_ids, TIME_COL, ID_COL, feature_types, None, folder_name, EXAMPLE_PATH, sent_name, job_id=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c5358-80ce-426b-9f5d-e9011ce7ad09",
   "metadata": {},
   "source": [
    "## Training for Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0775d359-6920-4ac5-8f29-6a52333f8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb_train = load_embeddings(\"Training/\" + llm_name + \"/\" + data_set + \"/sep_embeddings/\" + sent_name + \"/Features/\", start=0, num_files=1)\n",
    "X_tab_train = load_embeddings(\"Training/\" + llm_name + \"/\" + data_set + \"/sep_imputations/\" + sent_name+\"/Features/\", start=0, num_files=1)\n",
    "\n",
    "X_emb_test = load_embeddings(\"Testing/\" + llm_name + \"/\" + data_set + \"/sep_embeddings/\" + sent_name + \"/Features/\", start=0, num_files=1)\n",
    "X_tab_test = load_embeddings(\"Testing/\" + llm_name + \"/\" + data_set + \"/sep_imputations/\" + sent_name + \"/Features/\", start=0, num_files=1)\n",
    "\n",
    "targets_df = pd.read_csv(TARGET_FILE)[[ID_COL, TARGET_COL]]\n",
    "le = LabelEncoder()\n",
    "target_encoded = le.fit_transform(targets_df[TARGET_COL])\n",
    "targets_df[TARGET_COL] = target_encoded\n",
    "num_classes = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "475fcce1-4794-4922-9882-81b903799d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = X_tab_train.merge(X_emb_train, on=[ID_COL], how=\"inner\").merge(targets_df, on=[ID_COL], how=\"inner\")\n",
    "merged_train = merged_train.drop(columns=[ID_COL])\n",
    "\n",
    "merged_valtest = X_tab_test.merge(X_emb_test, on=[ID_COL], how=\"inner\").merge(targets_df, on=[ID_COL], how=\"inner\")\n",
    "merged_valtest = merged_valtest.drop(columns=[ID_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e06448-9a54-450a-a42e-b7d3b8f6b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_cols(method, merged_columns, tab_columns):\n",
    "    valid_cols = []\n",
    "    if method == 'tabular':\n",
    "        valid_cols = [c for c in merged_columns if ((c in tab_columns) or (c==TARGET_COL))]\n",
    "    elif method == 'merged':\n",
    "        valid_cols = list(merged_columns)\n",
    "    elif method == 'language':\n",
    "        valid_cols = [c for c in merged_columns if (c not in tab_columns)]\n",
    "    return valid_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b29cab47-a6da-423b-8d3c-6d3312a94e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From unseen data, select 15% for validation and 15% for testing\n",
    "merged_test, merged_val = train_test_split(merged_valtest, test_size=0.25, random_state=split_seed, stratify=merged_valtest[TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f307df9-978f-4756-9ef0-2a3dfb3e1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in [\"tabular\", \"merged\", \"language\"]:\n",
    "    folder_name =  data_set  + \"_\" + method\n",
    "    valid_cols = get_valid_cols(method, merged_train.columns, X_tab_train.columns)\n",
    "    df_train, df_val, df_test = merged_train[valid_cols], merged_val[valid_cols], merged_test[valid_cols]\n",
    "\n",
    "    for n_est in [100, 200, 300]:\n",
    "        for max_param in [3, 5, 7]:\n",
    "            for lr in [0.05, 0.1, 0.3]:\n",
    "                for λ in [0.01, 0.001, 1e-4, 1e-5, 0]:\n",
    "\n",
    "                    val_auc, val_acc, _ = train_xgb(df_train, df_val, TARGET_COL, n_est, max_param, lr, λ, num_classes)\n",
    "                    test_auc, test_acc, _ = train_xgb(pd.concat([df_train, df_val], axis=0), df_test, TARGET_COL, n_est, max_param, lr, λ, num_classes)\n",
    "                    target = TARGET_COL\n",
    "\n",
    "                    results = [target, val_auc, test_auc, str(df_train.shape), str(df_val.shape), str(df_test.shape),\n",
    "                               val_acc, test_acc, n_est, max_param, lr, λ, split_seed]\n",
    "\n",
    "                    column_list = [\"target\", \"val_auc\",  \"test_auc\",  \"train_size\", \"val_size\", \"test_size\", \n",
    "                                   \"val_acc\", \"test_acc\", \"n_est\", \"max_param\", \"lr\", \"lambda\", \"seed\"]\n",
    "\n",
    "                    df_results = pd.DataFrame(np.array([results])) \n",
    "\n",
    "                    if not os.path.exists(EXAMPLE_PATH + 'Results/'+llm_name + '/'+ sent_name + \"/\" ):\n",
    "                        os.makedirs(EXAMPLE_PATH + 'Results/'+ llm_name  +'/' + sent_name + \"/\" )\n",
    "\n",
    "                    # if file does not exist write header   \n",
    "                    if not os.path.isfile(EXAMPLE_PATH + 'Results/'+ llm_name  +'/' + sent_name + \"/\" + folder_name + \".csv\"):\n",
    "                        pd.DataFrame([column_list]).to_csv(EXAMPLE_PATH + 'Results/'+ llm_name +'/' + sent_name + \"/\" + folder_name + \".csv\", header=False)\n",
    "\n",
    "                    # else it exists so append without writing the header\n",
    "                    df_results.to_csv(EXAMPLE_PATH + 'Results/'+ llm_name  +'/'+ sent_name + \"/\" + folder_name + \".csv\",\n",
    "                                      mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ea883-f142-4dfe-a2a9-bb64c75936ba",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96da472d-9a79-4ab8-a8cc-dd009674a7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6705653021442495 0.72046783625731 0.7087719298245614\n"
     ]
    }
   ],
   "source": [
    "avg_tabular = 0\n",
    "avg_language = 0\n",
    "avg_merged = 0\n",
    "num_seeds = 1\n",
    "\n",
    "df_tab = pd.read_csv('Results/'+ llm_name  +'/' + sent_name + \"/\" + data_set +  '_tabular.csv')\n",
    "df_lang = pd.read_csv('Results/'+ llm_name  +'/' + sent_name + \"/\" + data_set + '_language.csv')\n",
    "df_merged = pd.read_csv('Results/'+ llm_name  +'/' + sent_name + \"/\" + data_set + '_merged.csv')\n",
    "\n",
    "tab_shape = (df_tab['train_size'].iloc[0], df_tab['val_size'].iloc[0], df_tab['test_size'].iloc[0])\n",
    "lang_shape = (df_lang['train_size'].iloc[0], df_lang['val_size'].iloc[0], df_lang['test_size'].iloc[0])\n",
    "merged_shape = (df_merged['train_size'].iloc[0], df_merged['val_size'].iloc[0], df_merged['test_size'].iloc[0])\n",
    "\n",
    "tab_size = eval(tab_shape[0])[0] +  eval(tab_shape[1])[0] +  eval(tab_shape[2])[0] \n",
    "lang_size = eval(lang_shape[0])[0] +  eval(lang_shape[1])[0] +  eval(lang_shape[2])[0] \n",
    "merged_size = eval(merged_shape[0])[0] +  eval(merged_shape[1])[0] +  eval(merged_shape[2])[0] \n",
    "\n",
    "assert(tab_size == lang_size)\n",
    "assert(merged_size == lang_size)\n",
    "\n",
    "for i in range(1):\n",
    "    dfi_tab = df_tab[df_tab['seed']==i]\n",
    "    dfi_lang = df_lang[df_lang['seed']==i]\n",
    "    dfi_merged = df_merged[df_merged['seed']==i]\n",
    "\n",
    "    auc_tab = dfi_tab[dfi_tab['val_auc'] == dfi_tab['val_auc'].max()]['test_auc'].mean()\n",
    "    auc_lang = dfi_lang[dfi_lang['val_auc'] == dfi_lang['val_auc'].max()]['test_auc'].mean()\n",
    "    auc_merged = dfi_merged[dfi_merged['val_auc'] == dfi_merged['val_auc'].max()]['test_auc'].mean()\n",
    "    \n",
    "    print(auc_tab, auc_lang,auc_merged )\n",
    "\n",
    "    avg_tabular += auc_tab\n",
    "    avg_language += auc_lang\n",
    "    avg_merged += auc_merged  \n",
    "\n",
    "avg_tabular = round(avg_tabular/num_seeds, 3)\n",
    "avg_language = round(avg_language/num_seeds, 3)\n",
    "avg_merged = round(avg_merged/num_seeds, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f89062-c9f2-4285-8bdc-c16ebf58a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular AUC:  0.671\n",
      "language AUC:  0.72\n",
      "merged AUC:  0.709\n"
     ]
    }
   ],
   "source": [
    "print(\"tabular AUC: \", avg_tabular)\n",
    "print(\"language AUC: \", avg_language)\n",
    "print(\"merged AUC: \", avg_merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipv",
   "language": "python",
   "name": "ipv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
