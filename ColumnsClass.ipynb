{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column(object):\n",
    "    def __init__(self, name, attribute, col_type, verb):\n",
    "        self.name = name\n",
    "        self.attribute = attribute\n",
    "        self.type = col_type\n",
    "        self.verb = verb\n",
    "        \n",
    "    def is_binary(self):\n",
    "        return self.type == \"binary\"\n",
    "    \n",
    "    def is_categorical(self):\n",
    "        return self.type == \"categorical\"\n",
    "    \n",
    "    def is_numerical(self):\n",
    "        return self.type == \"numerical\"\n",
    "    \n",
    "    def create_sentence(self, value, prefix, missing_word, replace_numbers, descriptive):\n",
    "        if descriptive:\n",
    "            return self.fn_descriptive(value, prefix, missing_word, replace_numbers)\n",
    "        else:\n",
    "            return self.fn_basic(value, prefix, missing_word, replace_numbers)\n",
    "        \n",
    "        \n",
    "class Binary_Column(Column):\n",
    "    def __init__(self, name, attribute, verb, neg_verb):\n",
    "        self.neg_verb = neg_verb\n",
    "        super().__init__(name, attribute, \"binary\", verb)\n",
    "        \n",
    "\n",
    "    def create_descriptive_sentence(self, value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if str(value).lower()  in [\"1\", \"0\", \"true\", \"false\"]:\n",
    "            if int(value) == 1:\n",
    "                sentence = prefix + self.verb + \" \" + self.attribute\n",
    "            elif int(value) == 0:\n",
    "                sentence = prefix + self.neg_verb + \" \" + self.attribute\n",
    "        return sentence\n",
    "            \n",
    "\n",
    "    def create_basic_sentence(self, value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if str(value).lower()  in [\"1\", \"0\", \"true\", \"false\"]:\n",
    "            if int(value) == 1:\n",
    "                sentence = self.verb + \" \" + self.attribute + \": yes\" \n",
    "            elif int(value) == 0:\n",
    "                sentence = self.neg_verb + \" \" + self.attribute + \": no\"\n",
    "        elif missing_word != \"\":\n",
    "            sentence = self.verb + \" \" + self.attribute + \": \" + missing_word\n",
    "        return sentence\n",
    "        \n",
    "class Categorical_Column(Column):\n",
    "    def __init__(self, name, attribute, verb):\n",
    "        super().__init__(name, attribute, \"categorical\", verb)\n",
    "\n",
    "    def create_descriptive_sentence(self, value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            sentence = prefix + self.attribute + \" \" + self.verb + \" \" + str(value)\n",
    "        elif  missing_word != \"\":\n",
    "            sentence = prefix + self.attribute + \" \" + self.verb + \" \" + missing_word\n",
    "        return sentence\n",
    "            \n",
    "\n",
    "    def create_basic_sentence(self, value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if  str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            sentence = self.attribute + \": \" + str(value)\n",
    "        elif missing_word != \"\":\n",
    "            sentence = self.attribute + \": \" + missing_word\n",
    "        return sentence\n",
    "    \n",
    "class Numerical_Column(Column):\n",
    "    def __init__(self, name, attribute, verb, avg, sd):\n",
    "        self.avg = avg\n",
    "        self.sd = sd\n",
    "        super().__init__(name, attribute, \"numerical\", verb)\n",
    "        \n",
    "        \n",
    "    def create_descriptive_sentence(self, value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            col_value = self.encode_number(value, replace_numbers)\n",
    "            sentence = prefix + self.attribute + \" \" + self.verb + \" \" + str(col_value) \n",
    "        elif  missing_word != \"\":\n",
    "            sentence = prefix + self.attribute + \" \" + self.verb + \" \" + missing_word \n",
    "        return sentence\n",
    "            \n",
    "\n",
    "    def create_basic_sentence(self, value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if  str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            col_value = self.encode_number(value, replace_numbers)\n",
    "            sentence = self.attribute + \": \" + str(col_value)\n",
    "        elif missing_word != \"\":\n",
    "            sentence = self.attribute + \": \" + missing_word\n",
    "        return sentence\n",
    "    \n",
    "    def encode_number(self, value, replace_numbers):\n",
    "        new_value = value\n",
    "        if replace_numbers:\n",
    "            if self.avg - 2*self.sd > value:\n",
    "                new_value = \"very low\"\n",
    "            elif self.avg - 2*self.sd <= value < self.avg - self.sd:\n",
    "                new_value = \"low\"\n",
    "            elif self.avg + 2*self.sd >= value > self.avg + self.sd:\n",
    "                new_value = \"high\"\n",
    "            elif self.avg + 2*self.sd < value:\n",
    "                new_value = \"very high\"\n",
    "            else:\n",
    "                new_value = \"normal\"\n",
    "        return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_col = Binary_Column(\"hisp\", \"hispanic\", \"is\", \"is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_col.create_descriptive_sentence(np.nan, \"the patient \",\"\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is hispanic: nan'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_col.create_basic_sentence(np.nan, \"the patient \",np.nan, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_col.create_descriptive_sentence(np.nan, \"the patient \",\"is missing\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = Categorical_Column(\"nat\", \"nationality\", \"is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = Numerical_Column(\"tmp\", \"temperature\",  \"is\", 10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import isnan\n",
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#One table per patient per tabular data structure\n",
    "class Table(object):\n",
    "    def __init__(self, name, df, columns, metadata, time_col):\n",
    "        self.name = name\n",
    "        self.headers = df.columns\n",
    "        self.columns = columns\n",
    "        self.metadata = metadata\n",
    "        self.df = df\n",
    "        self.time_col = time_col\n",
    "\n",
    "        \n",
    "    def create_weighted_text(self, prefix, missing_word, replace_numbers, descriptive):    \n",
    "        text = []\n",
    "        for t_i in range(self.df.shape[0]):\n",
    "            text_i = self.metadata\n",
    "            \n",
    "            for column in self.columns:\n",
    "                value = self.df[t_i, column.name]\n",
    "                text_i += column.create_sentence(value, prefix, missing_word, replace_numbers, descriptive) + \", \"\n",
    "                \n",
    "            text.append(text_i)\n",
    "    \n",
    "        self.df[\"text\"] = text \n",
    "\n",
    "    \n",
    "    def create_weighted_embeddings(self):\n",
    "        embeddings = []\n",
    "\n",
    "        for i in range(self.weighted_text.shape[0]):\n",
    "            text = self.weighted_text.iloc[i][\"text\"]\n",
    "            full_embedding = get_biobert_embeddings(text)[0]\n",
    "            embeddings.append(full_embedding.reshape(-1))\n",
    "\n",
    "        self.df[\"embeddings\"] = embeddings\n",
    "        \n",
    "    def create_timebounded_embeddings(self, start_hr, end_hr):\n",
    "        timebounded_df = self.df\n",
    "        \n",
    "        if start_hr is not None:\n",
    "            timebounded_df = timebounded_df[timebounded_df[time_col]>= start_hr]\n",
    "        if end_hr is not None:\n",
    "            timebounded_df = timebounded_df[timebounded_df[time_col]<= end_hr]\n",
    "            \n",
    "        timebound_df[\"weights\"] = create_time_weights(timebound_df[self.time_col])\n",
    "        \n",
    "        return timebound_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient(object):\n",
    "    def __init__(self, tables, pat_id, time_col):\n",
    "        self.id = pat_id\n",
    "        \n",
    "        for table in tables:\n",
    "            setattr(self, table.name , table)\n",
    "\n",
    "        \n",
    "    def create_embeddings(self, start_hr = None, end_hr = None, single_embedding=True):\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    def save_patient_object(obj, filepath):\n",
    "        with open(filepath, 'wb') as output:\n",
    "            pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # LOAD SINGLE PATIENT ICU STAY RECORDS FOR MIMIC-IV\n",
    "    def load_patient_object(filepath):\n",
    "        with open(filepath, 'rb') as input:  \n",
    "            return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables():\n",
    "    #TO_DO\n",
    "    \n",
    "def get_columns(attributes_map, verb_map, type_map):\n",
    "    #TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import isnan\n",
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    # Inputs:\n",
    "    #   text -> Input text (str)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   embeddings -> Final Biobert embeddings with vector dimensionality = (1,768)\n",
    "    #   hidden_embeddings -> Last hidden layer in Biobert model with vector dimensionality = (token_size,768)\n",
    "\n",
    "    # %% EXAMPLE OF USE\n",
    "    # embeddings, hidden_embeddings = get_biobert_embeddings(text)\n",
    "\n",
    "    tokens_pt = biobert_tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = biobert_model(**tokens_pt)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    pooler_output = outputs.pooler_output\n",
    "    hidden_embeddings = last_hidden_state.detach().numpy()\n",
    "    embeddings = pooler_output.detach().numpy()\n",
    "\n",
    "    return embeddings, hidden_embeddings\n",
    "\n",
    "def create_time_weights(timestamps):\n",
    "    #TO-DO\n",
    "    n = len(timestamps)\n",
    "    return [1/n for i in range(n)]\n",
    "\n",
    "\n",
    "# cleans up column strings \n",
    "def strip_df(df):\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = df[col].str.strip()\n",
    "        except:\n",
    "            None\n",
    "    return df\n",
    "\n",
    "# Some dataframes has columns with singular values, maybe we can delete these columns\n",
    "def unique_col(df):\n",
    "    lis_to_delete = []\n",
    "    for i in df.columns:\n",
    "        unique_val = df[i].unique()\n",
    "        if(len(unique_val) == 1):\n",
    "            print(i, unique_val)\n",
    "            lis_to_delete.append(i)\n",
    "    df = df[df.columns[~df.columns.isin(lis_to_delete)]]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_to_days(x):\n",
    "    days = x.astype('timedelta64[D]')\n",
    "    x = int(days/np.timedelta64(1, 'D'))\n",
    "    return x\n",
    "\n",
    "# Convert an entry to days\n",
    "def date_diff_hrs(t1, t0):\n",
    "    delta_t = round((t1-t0).total_seconds()/3600) # Result in hrs\n",
    "    return delta_t\n",
    "\n",
    "def compute_delta_time(df, starttime, time_col):\n",
    "    df['delta_time'] = df.apply(lambda x: date_diff_hrs(x['time_col'], starttime), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all patients have ALL data modalities, this filters so that the patient has records in all modalities in \n",
    "# df_lis\n",
    "def take_patient_intersection(df_lis, id_col):\n",
    "    intersection_id = set(df_lis[0][id_col].unique())\n",
    "\n",
    "    count = 1\n",
    "    while(count <= len(df_lis)):\n",
    "        intersection_id = intersection_id.intersection(set(df_lis[count][id_col].unique()))\n",
    "        \n",
    "    return intersection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_na(df, df_col):\n",
    "    return df[~df[df_col].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical with string to serial numbers\n",
    "def to_cat_from_str(df, df_col):\n",
    "    new_col_lis = []\n",
    "    for i in df_col:\n",
    "        if(type(df[i].values[0]) is str):\n",
    "            df[i + '_CODE'] = pd.Categorical(df[i]).codes\n",
    "            new_col_lis.append(i + '_CODE')\n",
    "        else:\n",
    "            new_col_lis.append(i)\n",
    "            \n",
    "    return df[new_col_lis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height was in the format of 5' 3'', change it to cm\n",
    "def change_height_from_str(age_list):\n",
    "    demo_cm_lis = []\n",
    "    for i in age_list:\n",
    "        try:\n",
    "            converted = round(float(i.split()[1][:-1]) * 2.54 + float(i.split()[0][:-1]) * 30.48, 3)\n",
    "            demo_cm_lis.append(converted)\n",
    "        except:\n",
    "            demo_cm_lis.append(np.nan)\n",
    "\n",
    "\n",
    "    return demo_cm_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_meta_info():\n",
    "    dict_meta = {'demo': 'The following is the demographics information of this patient, which describes ...\\\n",
    "    information such as name, date of birth and address, along with insurance information.', \n",
    "     \n",
    "     'encounter': 'The following is the encounter information of this patient, which describes the ...\\\n",
    "        medical information submitted by health care providers (physicians, hospitals, Ancillaries, etc.) ...\\\n",
    "        which documents both the clinical conditions, services and items delivered to the member to treat ...\\\n",
    "        their conditions.',\n",
    "     \n",
    "     'medication': 'The following is the medication information of this patient, which describes the ...\\\n",
    "        chemicals that are used to cure, halt, or prevent disease; ease symptoms; or help in the diagnosis ...\\\n",
    "        of illnesses.', \n",
    "                 \n",
    "     'problem': 'The following is the problem information of this patient, which describes the ...\\\n",
    "        disease, condition, or injury from a patient signs and symptoms.', \n",
    "     \n",
    "     'sign': 'The following is the signs information of this patient, which describes the ...\\\n",
    "        physical response linked medical fact or characteristic that is detected by a physician, nurse, ...\\\n",
    "        or medical device during the examination of a patient.', \n",
    "     \n",
    "     'social': 'The following is the social information of this patient, which describes the ...\\\n",
    "        the circumstances of the places where people reside, work, learn, and engage in recreation.', \n",
    "    }\n",
    "    \n",
    "    return dict_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For RRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df_name, id_col):\n",
    "    df = pd.read_csv(df_name)\n",
    "    df = strip_df(df)\n",
    "    df = unique_col(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_to_patient(df, id_to_include):\n",
    "    df = df[df[id_col].isin(id_to_include)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time(df, df_col):\n",
    "    df[df_col] = pd.to_datetime(df[df_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_RRT_col_include = {demo: ['PAT_CLASS', 'SEX_CODE', 'ETHNICITY', 'age', 'RACE_CODE', 'FIRST_THREE_DIGITS_ZIP',\n",
    "            'HEIGHT_CM', 'LOC_NAME', 'WEIGHT'],\n",
    "                encounter: ['BP_DIASTOLIC', 'BMI', 'WEIGHT', 'BP_SYSTOLIC', 'TEMPERATURE', 'BSA', \n",
    "           'PULSE','RESPIRATIONS', 'HEIGHT_CM'],\n",
    "                medicine: ['DOSE', 'DOSE_UNIT', 'MED_NAME'], \n",
    "                problem: ['DX_NAME', 'DX_GROUP', 'CURRENT_ICD10_LIST', 'PRINCIPAL_PROB_YN'], \n",
    "                social: ['TOBACCO_PAK_PER_DY', 'TOBACCO_COMMENT', 'SMOKING_STATUS', 'ALCOHOL_OZ_PER_WK',\n",
    "          'USES_ALCOHOL', 'ALCOHOL_COMMENT', 'ILLICIT_DRUG_USER', 'ILLICIT_DRUG_FREQ', \n",
    "          'CIGARETTES_YN', 'PIPES_YN', 'SNUFF_YN', 'CHEW_YN', 'IV_DRUG_USER_YN'],\n",
    "                sign: ['MEAS_VALUE', 'FLO_MEAS_NAME']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_RRT_col_time = {demo: 'INP_ADM_DATE', \n",
    "                    encounter: 'CONTACT_DATE',\n",
    "                    medicine:'PERFORMEDFROMDTM', \n",
    "                    problem: 'NOTED_DATE', \n",
    "                    social: 'CONTACT_DATE', \n",
    "                    sign: 'dtDateRec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'PAT_ENC_CSN_GUID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = load_data('Data/Full_Encounter.txt', 'PAT_ENC_CSN_GUID')\n",
    "encounter = load_data('../../RRR-full/Full_Encounter.txt', 'PAT_ENC_CSN_GUID')\n",
    "med = load_data('../../RRR-full/Full_Meds.txt', 'PAT_ENC_CSN_GUID')\n",
    "problem = load_data('../../RRR-full/Full_ProblemList.txt', 'PAT_ENC_CSN_GUID')\n",
    "sign = load_data('../../RRR-full/Full_SignsSymptoms.txt', 'PAT_ENC_CSN_GUID')\n",
    "social = load_data('../../RRR-full/Full_SocialHx.txt', 'PAT_ENC_CSN_GUID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_include = take_patient_intersection([demo, encounter, med, problem, sign, social], id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo['HEIGHT_cm'] = change_height_from_str(demo['HEIGHT'])\n",
    "encounter['HEIGHT_cm'] = change_height_from_str(encounter['HEIGHT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [demo, encounter, med, problem, sign, social]:\n",
    "    df_col = dict_RRT_col_include[df]\n",
    "    to_cat_from_str(df, df_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructs patient objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for id_is in tqdm(id_to_include):\n",
    "    patient_redcap = redcap[redcap[id_col] == id_is]\n",
    "    end_time_point = patient_redcap['DateTime'].values[0]\n",
    "\n",
    "    patient_encounter = encounter[encounter[id_col] == id_is]\n",
    "    admit_time = patient_encounter['HOSP_ADMSN_TIME'].values[0]\n",
    "    admit_time = (pd.Series(admit_time) + pd.DateOffset(-1)).values[0]\n",
    "    dischrg_time = patient_encounter['HOSP_DISCHRG_TIME'].values[0]\n",
    "\n",
    "    patient_demo = demo[demo[id_col] == id_is]\n",
    "    patient_med = med[med[id_col] == id_is]\n",
    "    patient_prob = problem[problem[id_col] == id_is]\n",
    "    patient_sign = sign[sign[id_col] == id_is]\n",
    "    patient_social = social[social[id_col] == id_is]\n",
    "    \n",
    "    patient_med = filter_na(patient_med, 'PERFORMEDFROMDTM')\n",
    "    patient_prob = filter_na(patient_prob, 'NOTED_DATE')\n",
    "    patient_sign = filter_na(patient_sign, 'dtDateRec')\n",
    "    patient_social = filter_na(patient_social, 'CONTACT_DATE')\n",
    "    \n",
    "    if((len(patient_med) != 0) & (len(patient_prob) != 0) & (len(patient_sign) != 0) & (len(patient_social) != 0)):\n",
    "        patient_med_time = restrict_df_by_redcap(patient_med, 'PERFORMEDFROMDTM', end_time_point, admit_time)\n",
    "        patient_prob_time = restrict_df_by_redcap(patient_prob, 'NOTED_DATE', end_time_point, admit_time)\n",
    "        patient_sign_time = restrict_df_by_redcap(patient_sign, 'dtDateRec', end_time_point, admit_time)\n",
    "        patient_social_time = restrict_df_by_redcap(patient_social, 'CONTACT_DATE', end_time_point, admit_time)\n",
    "    \n",
    "    if((len(patient_med_time) != 0) & (len(patient_prob_time) != 0) & (len(patient_sign_time) != 0) & (len(patient_social_time) != 0)):\n",
    "        total += 1\n",
    "        patient_obj = Patient(id_is, end_time_point, admit_time, dischrg_time, patient_demo, patient_encounter, \n",
    "                              patient_redcap, patient_sign_time, patient_med_time, patient_prob_time, \n",
    "                              patient_social_time)\n",
    "\n",
    "        save_patient_object(patient_obj, f'tabtext_paper_obj/obj_{id_is}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make strings out of the objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
